{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analytics and Machine Learning in Finance\n",
    "##  Assignment: M&A Target Prediction Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid teal\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:teal\">Write your submission into this solution file</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data set and extract X and y using `.pop`. (1P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "mydata=pd.read_excel(\"X_and_y.xlsx\")\n",
    "\n",
    "x=mydata.copy()\n",
    "y=x.pop('target_dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Display the dimensions of the data set. (1P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17973, 28)\n"
     ]
    }
   ],
   "source": [
    "# Your solution:\n",
    "print(mydata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Display the first 10 rows of the data set. (1P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_dummy</th>\n",
       "      <th>year</th>\n",
       "      <th>act</th>\n",
       "      <th>at</th>\n",
       "      <th>capx</th>\n",
       "      <th>ch</th>\n",
       "      <th>che</th>\n",
       "      <th>csho</th>\n",
       "      <th>dlc</th>\n",
       "      <th>dltt</th>\n",
       "      <th>...</th>\n",
       "      <th>ppent</th>\n",
       "      <th>prstkc</th>\n",
       "      <th>pstkc</th>\n",
       "      <th>sale</th>\n",
       "      <th>seq</th>\n",
       "      <th>xint</th>\n",
       "      <th>xrd</th>\n",
       "      <th>prcc_c</th>\n",
       "      <th>prcc_f</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>68.760</td>\n",
       "      <td>108.171</td>\n",
       "      <td>8.742</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.608</td>\n",
       "      <td>26.690</td>\n",
       "      <td>58.411</td>\n",
       "      <td>...</td>\n",
       "      <td>18.658</td>\n",
       "      <td>0.000</td>\n",
       "      <td>35.147</td>\n",
       "      <td>165.542</td>\n",
       "      <td>-19.688</td>\n",
       "      <td>10.929</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.261</td>\n",
       "      <td>5.987</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>19.147</td>\n",
       "      <td>1.928</td>\n",
       "      <td>0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>3.713</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.725</td>\n",
       "      <td>-0.604</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1404.000</td>\n",
       "      <td>7067.000</td>\n",
       "      <td>672.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>46.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1883.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4708.000</td>\n",
       "      <td>5781.000</td>\n",
       "      <td>58.000</td>\n",
       "      <td>1273.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>76.508</td>\n",
       "      <td>423.184</td>\n",
       "      <td>16.484</td>\n",
       "      <td>6.411</td>\n",
       "      <td>6.411</td>\n",
       "      <td>8.938</td>\n",
       "      <td>0.118</td>\n",
       "      <td>201.587</td>\n",
       "      <td>...</td>\n",
       "      <td>150.979</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>496.311</td>\n",
       "      <td>117.942</td>\n",
       "      <td>23.202</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.1250</td>\n",
       "      <td>9.7500</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>148.884</td>\n",
       "      <td>190.250</td>\n",
       "      <td>10.730</td>\n",
       "      <td>0.000</td>\n",
       "      <td>112.447</td>\n",
       "      <td>329.764</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>150.491</td>\n",
       "      <td>150.852</td>\n",
       "      <td>5.845</td>\n",
       "      <td>39.380</td>\n",
       "      <td>22.5625</td>\n",
       "      <td>22.5625</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>335.256</td>\n",
       "      <td>355.191</td>\n",
       "      <td>12.366</td>\n",
       "      <td>139.917</td>\n",
       "      <td>300.525</td>\n",
       "      <td>47.508</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.134</td>\n",
       "      <td>...</td>\n",
       "      <td>12.975</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>87.059</td>\n",
       "      <td>313.640</td>\n",
       "      <td>0.189</td>\n",
       "      <td>26.451</td>\n",
       "      <td>49.3750</td>\n",
       "      <td>19.0700</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>19992.242</td>\n",
       "      <td>0.000</td>\n",
       "      <td>719.487</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1968.129</td>\n",
       "      <td>2329.264</td>\n",
       "      <td>...</td>\n",
       "      <td>457.637</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1480.462</td>\n",
       "      <td>752.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.8750</td>\n",
       "      <td>23.8750</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>354.642</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16.005</td>\n",
       "      <td>16.044</td>\n",
       "      <td>4.218</td>\n",
       "      <td>9.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.749</td>\n",
       "      <td>28.788</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16.2500</td>\n",
       "      <td>16.2500</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>13.037</td>\n",
       "      <td>38.929</td>\n",
       "      <td>1.234</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.307</td>\n",
       "      <td>5.128</td>\n",
       "      <td>1.878</td>\n",
       "      <td>18.941</td>\n",
       "      <td>...</td>\n",
       "      <td>11.068</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>46.201</td>\n",
       "      <td>11.833</td>\n",
       "      <td>1.792</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.4375</td>\n",
       "      <td>1.4375</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>188.954</td>\n",
       "      <td>332.089</td>\n",
       "      <td>22.173</td>\n",
       "      <td>32.751</td>\n",
       "      <td>43.733</td>\n",
       "      <td>52.530</td>\n",
       "      <td>25.436</td>\n",
       "      <td>32.820</td>\n",
       "      <td>...</td>\n",
       "      <td>36.630</td>\n",
       "      <td>51.081</td>\n",
       "      <td>0.000</td>\n",
       "      <td>398.895</td>\n",
       "      <td>191.169</td>\n",
       "      <td>5.808</td>\n",
       "      <td>42.338</td>\n",
       "      <td>46.9375</td>\n",
       "      <td>46.9375</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_dummy  year       act         at     capx       ch      che  \\\n",
       "0             0  2000    68.760    108.171    8.742    0.578    0.578   \n",
       "1             0  2000     0.261      5.987    0.823    0.005    0.005   \n",
       "2             0  2000  1404.000   7067.000  672.000    0.000    0.000   \n",
       "3             0  2000    76.508    423.184   16.484    6.411    6.411   \n",
       "4             0  2000   148.884    190.250   10.730    0.000  112.447   \n",
       "5             0  2000   335.256    355.191   12.366  139.917  300.525   \n",
       "6             0  2000     0.000  19992.242    0.000  719.487    0.000   \n",
       "7             0  2000     0.000    354.642    0.000   16.005   16.044   \n",
       "8             0  2000    13.037     38.929    1.234    0.307    0.307   \n",
       "9             0  2000   188.954    332.089   22.173   32.751   43.733   \n",
       "\n",
       "      csho       dlc      dltt  ...     ppent  prstkc   pstkc      sale  \\\n",
       "0    0.608    26.690    58.411  ...    18.658   0.000  35.147   165.542   \n",
       "1   19.147     1.928     0.012  ...     3.713   0.000   0.001     1.725   \n",
       "2    0.000    14.000    46.000  ...  1883.000   0.000   0.000  4708.000   \n",
       "3    8.938     0.118   201.587  ...   150.979   0.000   0.000   496.311   \n",
       "4  329.764     0.000     0.000  ...    22.222   0.000   0.000   150.491   \n",
       "5   47.508     0.359     0.134  ...    12.975   0.000   0.000    87.059   \n",
       "6    0.000  1968.129  2329.264  ...   457.637   0.000   0.000     0.000   \n",
       "7    4.218     9.700     0.000  ...     9.210   0.000   0.000    27.749   \n",
       "8    5.128     1.878    18.941  ...    11.068   0.999   0.000    46.201   \n",
       "9   52.530    25.436    32.820  ...    36.630  51.081   0.000   398.895   \n",
       "\n",
       "        seq     xint       xrd   prcc_c   prcc_f  industry  \n",
       "0   -19.688   10.929     0.000   0.0000   0.0000        42  \n",
       "1    -0.604    0.158     0.000   1.1250   1.1250         8  \n",
       "2  5781.000   58.000  1273.000   0.0000   0.0000        37  \n",
       "3   117.942   23.202     0.000   9.1250   9.7500         8  \n",
       "4   150.852    5.845    39.380  22.5625  22.5625        48  \n",
       "5   313.640    0.189    26.451  49.3750  19.0700        36  \n",
       "6  1480.462  752.044     0.000  23.8750  23.8750        45  \n",
       "7    28.788    0.000     0.000  16.2500  16.2500        45  \n",
       "8    11.833    1.792     0.000   1.4375   1.4375        20  \n",
       "9   191.169    5.808    42.338  46.9375  46.9375        34  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your solution:\n",
    "mydata.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Produce summary statistics of the file. (1P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_dummy</th>\n",
       "      <th>year</th>\n",
       "      <th>act</th>\n",
       "      <th>at</th>\n",
       "      <th>capx</th>\n",
       "      <th>ch</th>\n",
       "      <th>che</th>\n",
       "      <th>csho</th>\n",
       "      <th>dlc</th>\n",
       "      <th>dltt</th>\n",
       "      <th>...</th>\n",
       "      <th>ppent</th>\n",
       "      <th>prstkc</th>\n",
       "      <th>pstkc</th>\n",
       "      <th>sale</th>\n",
       "      <th>seq</th>\n",
       "      <th>xint</th>\n",
       "      <th>xrd</th>\n",
       "      <th>prcc_c</th>\n",
       "      <th>prcc_f</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>1.797300e+04</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "      <td>17973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.077561</td>\n",
       "      <td>2004.377900</td>\n",
       "      <td>597.696315</td>\n",
       "      <td>1.649849e+04</td>\n",
       "      <td>132.098802</td>\n",
       "      <td>473.731032</td>\n",
       "      <td>1037.329036</td>\n",
       "      <td>102.972631</td>\n",
       "      <td>1638.306935</td>\n",
       "      <td>2417.730249</td>\n",
       "      <td>...</td>\n",
       "      <td>930.586977</td>\n",
       "      <td>53.792161</td>\n",
       "      <td>4.659975</td>\n",
       "      <td>2194.985243</td>\n",
       "      <td>1712.417719</td>\n",
       "      <td>205.455292</td>\n",
       "      <td>36.250328</td>\n",
       "      <td>120.015187</td>\n",
       "      <td>119.939028</td>\n",
       "      <td>32.254048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.267487</td>\n",
       "      <td>2.863942</td>\n",
       "      <td>2744.912526</td>\n",
       "      <td>1.205644e+05</td>\n",
       "      <td>771.230674</td>\n",
       "      <td>3426.481270</td>\n",
       "      <td>12944.636638</td>\n",
       "      <td>455.104133</td>\n",
       "      <td>18216.565326</td>\n",
       "      <td>18094.740821</td>\n",
       "      <td>...</td>\n",
       "      <td>4537.035571</td>\n",
       "      <td>567.200100</td>\n",
       "      <td>77.957874</td>\n",
       "      <td>10550.387774</td>\n",
       "      <td>8232.750686</td>\n",
       "      <td>1864.693598</td>\n",
       "      <td>249.621390</td>\n",
       "      <td>3163.470372</td>\n",
       "      <td>3163.471695</td>\n",
       "      <td>14.291293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>-0.168000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-330.000000</td>\n",
       "      <td>-0.134000</td>\n",
       "      <td>-0.134000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4234.472000</td>\n",
       "      <td>-13593.000000</td>\n",
       "      <td>-0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.183400e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.622000</td>\n",
       "      <td>0.474000</td>\n",
       "      <td>3.169000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.803000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.078000</td>\n",
       "      <td>15.278000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.135000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>14.923000</td>\n",
       "      <td>3.845650e+02</td>\n",
       "      <td>1.328000</td>\n",
       "      <td>16.166000</td>\n",
       "      <td>13.302000</td>\n",
       "      <td>16.102000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>26.804000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.136000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.134000</td>\n",
       "      <td>91.934000</td>\n",
       "      <td>2.077000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.050000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>170.088000</td>\n",
       "      <td>1.899536e+03</td>\n",
       "      <td>20.666000</td>\n",
       "      <td>78.906000</td>\n",
       "      <td>84.400000</td>\n",
       "      <td>49.835000</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>352.583000</td>\n",
       "      <td>...</td>\n",
       "      <td>167.502000</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>587.762000</td>\n",
       "      <td>495.600000</td>\n",
       "      <td>28.235000</td>\n",
       "      <td>2.254000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>23.390000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>80202.000000</td>\n",
       "      <td>3.001251e+06</td>\n",
       "      <td>22658.000000</td>\n",
       "      <td>134308.969000</td>\n",
       "      <td>592643.965000</td>\n",
       "      <td>28483.267000</td>\n",
       "      <td>605462.506000</td>\n",
       "      <td>542569.195000</td>\n",
       "      <td>...</td>\n",
       "      <td>108275.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>7839.000000</td>\n",
       "      <td>361143.000000</td>\n",
       "      <td>231444.000000</td>\n",
       "      <td>72187.010000</td>\n",
       "      <td>6506.000000</td>\n",
       "      <td>141600.000000</td>\n",
       "      <td>141600.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_dummy          year           act            at          capx  \\\n",
       "count  17973.000000  17973.000000  17973.000000  1.797300e+04  17973.000000   \n",
       "mean       0.077561   2004.377900    597.696315  1.649849e+04    132.098802   \n",
       "std        0.267487      2.863942   2744.912526  1.205644e+05    771.230674   \n",
       "min        0.000000   2000.000000     -0.168000  0.000000e+00   -330.000000   \n",
       "25%        0.000000   2002.000000      0.000000  5.183400e+01      0.000000   \n",
       "50%        0.000000   2004.000000     14.923000  3.845650e+02      1.328000   \n",
       "75%        0.000000   2007.000000    170.088000  1.899536e+03     20.666000   \n",
       "max        1.000000   2009.000000  80202.000000  3.001251e+06  22658.000000   \n",
       "\n",
       "                  ch            che          csho            dlc  \\\n",
       "count   17973.000000   17973.000000  17973.000000   17973.000000   \n",
       "mean      473.731032    1037.329036    102.972631    1638.306935   \n",
       "std      3426.481270   12944.636638    455.104133   18216.565326   \n",
       "min        -0.134000      -0.134000      0.000000       0.000000   \n",
       "25%         2.622000       0.474000      3.169000       0.002000   \n",
       "50%        16.166000      13.302000     16.102000       3.000000   \n",
       "75%        78.906000      84.400000     49.835000      47.500000   \n",
       "max    134308.969000  592643.965000  28483.267000  605462.506000   \n",
       "\n",
       "                dltt  ...          ppent        prstkc         pstkc  \\\n",
       "count   17973.000000  ...   17973.000000  17973.000000  17973.000000   \n",
       "mean     2417.730249  ...     930.586977     53.792161      4.659975   \n",
       "std     18094.740821  ...    4537.035571    567.200100     77.957874   \n",
       "min         0.000000  ...       0.000000      0.000000      0.000000   \n",
       "25%         0.033000  ...       1.803000      0.000000      0.000000   \n",
       "50%        26.804000  ...      16.136000      0.000000      0.000000   \n",
       "75%       352.583000  ...     167.502000      0.026000      0.000000   \n",
       "max    542569.195000  ...  108275.000000  45000.000000   7839.000000   \n",
       "\n",
       "                sale            seq          xint           xrd  \\\n",
       "count   17973.000000   17973.000000  17973.000000  17973.000000   \n",
       "mean     2194.985243    1712.417719    205.455292     36.250328   \n",
       "std     10550.387774    8232.750686   1864.693598    249.621390   \n",
       "min     -4234.472000  -13593.000000     -0.090000      0.000000   \n",
       "25%         2.078000      15.278000      0.008000      0.000000   \n",
       "50%        66.134000      91.934000      2.077000      0.000000   \n",
       "75%       587.762000     495.600000     28.235000      2.254000   \n",
       "max    361143.000000  231444.000000  72187.010000   6506.000000   \n",
       "\n",
       "              prcc_c         prcc_f      industry  \n",
       "count   17973.000000   17973.000000  17973.000000  \n",
       "mean      120.015187     119.939028     32.254048  \n",
       "std      3163.470372    3163.471695     14.291293  \n",
       "min         0.000000       0.000000      0.000000  \n",
       "25%         1.100000       1.135000     21.000000  \n",
       "50%         9.050000       9.040000     36.000000  \n",
       "75%        23.500000      23.390000     45.000000  \n",
       "max    141600.000000  141600.000000     49.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your solution:\n",
    "mydata.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Display categorical variables in the data set. (1P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_dummy</th>\n",
       "      <th>year</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17968</th>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17969</th>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17970</th>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17971</th>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17972</th>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17973 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_dummy  year  industry\n",
       "0                 0  2000        42\n",
       "1                 0  2000         8\n",
       "2                 0  2000        37\n",
       "3                 0  2000         8\n",
       "4                 0  2000        48\n",
       "...             ...   ...       ...\n",
       "17968             1  2009        30\n",
       "17969             0  2009         7\n",
       "17970             1  2009        45\n",
       "17971             0  2009        43\n",
       "17972             0  2009        34\n",
       "\n",
       "[17973 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your solution:\n",
    "cat_var=mydata.select_dtypes(include=[\"int\"])\n",
    "cat_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create a dummy variable that is called `Dividend_Payer`. It shall take on a value of 1 if the firm pays dividends, and zero otherwise. (1P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        1\n",
      "4        0\n",
      "        ..\n",
      "17968    0\n",
      "17969    0\n",
      "17970    1\n",
      "17971    0\n",
      "17972    0\n",
      "Name: Dividend_Payer, Length: 17973, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Your solution:\n",
    "def dividends(dvc):\n",
    "    if pd.notna(dvc) and dvc>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "mydata[\"Dividend_Payer\"]=mydata[\"dvc\"].apply(dividends)\n",
    "print(mydata[\"Dividend_Payer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Split the data set into train and test data set (80:20). (1P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the following tasks, print the performance on the train set and the test set:\n",
    "8. Run a logistic regression without any regularization. If the model is not converging, try setting: `max_iter=5000`. (2P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Deal       0.92      1.00      0.96      3319\n",
      "        Deal       0.33      0.00      0.01       276\n",
      "\n",
      "    accuracy                           0.92      3595\n",
      "   macro avg       0.63      0.50      0.48      3595\n",
      "weighted avg       0.88      0.92      0.89      3595\n",
      "\n",
      "0.9225900681596884 0.9229485396383866\n"
     ]
    }
   ],
   "source": [
    "# Your solution:\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "mymodel1=LogisticRegression(penalty=None, max_iter=5000, random_state=42)\n",
    "mymodel1.fit(x_train, y_train)\n",
    "y_predict1=mymodel1.predict(x_test)\n",
    "\n",
    "# Looking at the performance of this model:\n",
    "cf_matrix1=confusion_matrix(y_test, y_predict1)\n",
    "target_names=[\"No Deal\", \"Deal\"]\n",
    "print(classification_report(y_test, y_predict1, target_names=target_names))\n",
    "\n",
    "score_train=mymodel1.score(x_train, y_train)\n",
    "score_test=mymodel1.score(x_test, y_test)\n",
    "print(score_train, score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Run a logistic regression with elastic net with regularization that is stronger than the default setting. If the model is not converging, try setting: `max_iter=5000`. (2P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Deal       0.92      1.00      0.96      3319\n",
      "        Deal       0.00      0.00      0.00       276\n",
      "\n",
      "    accuracy                           0.92      3595\n",
      "   macro avg       0.46      0.50      0.48      3595\n",
      "weighted avg       0.85      0.92      0.89      3595\n",
      "\n",
      "0.9225205174572263 0.9229485396383866\n"
     ]
    }
   ],
   "source": [
    "# Your solution:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mymodel2=LogisticRegression(penalty=\"elasticnet\", C=0.1, solver=\"saga\", l1_ratio=0.5, max_iter=5000, random_state=42)\n",
    "mymodel2.fit(x_train, y_train)\n",
    "y_predict2=mymodel2.predict(x_test)\n",
    "\n",
    "# Looking at the performance of this model:\n",
    "cf_matrix2=confusion_matrix(y_test, y_predict2)\n",
    "target_names=[\"No Deal\", \"Deal\"]\n",
    "print(classification_report(y_test, y_predict2, target_names=target_names))\n",
    "\n",
    "score_train2=mymodel2.score(x_train, y_train)\n",
    "score_test2=mymodel2.score(x_test, y_test)\n",
    "print(score_train2, score_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Run a SVC model with regularization stronger than the default setting. If the model is not converging, try setting: `max_iter=5000`. (2P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9222423146473779 0.9232267037552155\n"
     ]
    }
   ],
   "source": [
    "# Your solution:\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "x_trscaled=scale(x_train)\n",
    "x_ttscaled=scale(x_test)\n",
    "mymodel3=SVC(C=0.1, random_state=42)\n",
    "mymodel3.fit(x_trscaled, y_train)\n",
    "y_predict3=mymodel3.predict(x_ttscaled)\n",
    "\n",
    "# Looking at the performance of this model:\n",
    "\n",
    "score_train3=mymodel3.score(x_trscaled, y_train)\n",
    "score_test3=mymodel3.score(x_ttscaled, y_test)\n",
    "print(score_train3, score_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Run a random forest model with 300 trees and with a depth that can be termed \"shallow\". Hint: refer to the slides. Also, set the `random_state` to some integer of your choice. (2P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9222423146473779 0.9232267037552155\n"
     ]
    }
   ],
   "source": [
    "# Your solution:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mymodel4rf=RandomForestClassifier(n_estimators = 300, random_state=42, max_depth=4)\n",
    "mymodel4rf.fit(x_train, y_train)\n",
    "\n",
    "y_predict4=mymodel4rf.predict(x_test)\n",
    "\n",
    "# Looking at the performance of this model:\n",
    "\n",
    "score_train4=mymodel4rf.score(x_train, y_train)\n",
    "score_test4=mymodel4rf.score(x_test, y_test)\n",
    "print(score_train4, score_test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Run a gradient boosting model with the number of boosting stages that is larger than that in the default settings. (2P) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Deal       0.93      1.00      0.96      3319\n",
      "        Deal       0.78      0.15      0.25       276\n",
      "\n",
      "    accuracy                           0.93      3595\n",
      "   macro avg       0.86      0.57      0.61      3595\n",
      "weighted avg       0.92      0.93      0.91      3595\n",
      "\n",
      "0.942759771873696 0.9315716272600835\n"
     ]
    }
   ],
   "source": [
    "# Your solution:\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "mymodel5=GradientBoostingClassifier(n_estimators=300, random_state=42)\n",
    "mymodel5.fit(x_train, y_train)\n",
    "y_predict5=mymodel5.predict(x_test)\n",
    "\n",
    "# Looking at the performance of this model:\n",
    "\n",
    "cf_matrix5=confusion_matrix(y_test, y_predict5)\n",
    "target_names=[\"No Deal\", \"Deal\"]\n",
    "print(classification_report(y_test, y_predict5, target_names=target_names))\n",
    "\n",
    "score_train5=mymodel5.score(x_train, y_train)\n",
    "score_test5=mymodel5.score(x_test, y_test)\n",
    "print(score_train5, score_test5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Run a neural network model with two hidden layers. Your model should have 10 units in the first layer and 17 hidden units in the second layer. In addition, apply regularization that is weaker than the default setting, `max_iter=1000` and the remaning setttings set at default. Also, set the `random_state` to some integer of your choice. (2P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Deal       0.93      0.99      0.96      3319\n",
      "        Deal       0.33      0.04      0.08       276\n",
      "\n",
      "    accuracy                           0.92      3595\n",
      "   macro avg       0.63      0.52      0.52      3595\n",
      "weighted avg       0.88      0.92      0.89      3595\n",
      "\n",
      "0.9255807483655585 0.9198887343532685\n"
     ]
    }
   ],
   "source": [
    "# Your solution:\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "x_trscaled2=scale(x_train)\n",
    "x_ttscaled2=scale(x_test)\n",
    "\n",
    "mymodel6=MLPClassifier(hidden_layer_sizes=(10, 17), alpha=0.000001, max_iter=1000, random_state=42)\n",
    "mymodel6.fit(x_trscaled2, y_train)\n",
    "y_predict6=mymodel6.predict(x_ttscaled2)\n",
    "\n",
    "# Looking at the performance of this model:\n",
    "cf_matrix6=confusion_matrix(y_test, y_predict6)\n",
    "target_names=[\"No Deal\", \"Deal\"]\n",
    "print(classification_report(y_test, y_predict6, target_names=target_names))\n",
    "\n",
    "score_train6=mymodel6.score(x_trscaled2, y_train)\n",
    "score_test6=mymodel6.score(x_ttscaled2, y_test)\n",
    "print(score_train6, score_test6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following task, run grid search with 7-fold cross validation (CV), show the CV figure (heatmap), show the best parameters and briefly comment on your result.\n",
    "\n",
    "14. Run an algorithm of your choice that has at least two hyperparameters to tune. For each of the hyperparameters, try at least two values. (6P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.5, 'gamma': 100}\n",
      "Best CV-score: 0.9237724301015441\n",
      "Best estimator: SVC(C=0.5, gamma=100, max_iter=30000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your solution:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, train_size=0.8)\n",
    "\n",
    "scaler2=StandardScaler().fit(x)\n",
    "standxtrain=pd.DataFrame(scaler2.fit_transform(x_train))\n",
    "standxtest=pd.DataFrame(scaler2.fit_transform(x_test))\n",
    "\n",
    "parameters_grid={\"C\":[0.2, 0.5, 1.0],\n",
    "                 \"gamma\":[0.1, 10, 100, 250]}\n",
    "\n",
    "mygrid_search=GridSearchCV(SVC(max_iter=30000), parameters_grid, cv=7)\n",
    "mygrid_search.fit(standxtrain, y_train) \n",
    "\n",
    "print(\"Best parameters: {}\".format(mygrid_search.best_params_))\n",
    "print(\"Best CV-score: {}\".format(mygrid_search.best_score_))\n",
    "print(\"Best estimator: {}\".format(mygrid_search.best_estimator_))\n",
    "\n",
    "mylastresults=pd.DataFrame(mygrid_search.cv_results_)\n",
    "pivottable=pd.pivot_table(pd.DataFrame(mygrid_search.cv_results_), values=\"mean_test_score\", index=\"param_C\", columns=\"param_gamma\")\n",
    "\n",
    "picture=sns.heatmap(pivottable, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heatmap shows two important hyperparameters of the SVC model: C on the y-axis & gamma on the x-axis. C range was from 0.2 to 1.0 and gamma range was from 0.1 to 250. \n",
    "The overall performance does not vary a lot and for all the parameters ranges from 0.9222 to 0.9229, which signals a good performance with these parameters. Darker colors signal higher performance, and the the best performance of 0.9229 can be seen with the parameters C=0.5 and gamma=250."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid teal\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:teal\">Instructions for submitting the file:</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Jupyter Notebook and rename it as your StudentID.\n",
    "For example, if your ID was `'1234567'`, your file would be saved as `'1234567.ipynb'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© Copyright. 2024. Prof. Dr. Kornelia Fabisik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
